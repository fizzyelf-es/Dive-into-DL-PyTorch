{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c15703f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3b7ea9",
   "metadata": {},
   "source": [
    "  创建一个5*3的未初始化的tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db297d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9.2755e-39, 9.1837e-39, 9.3674e-39],\n",
      "        [1.0745e-38, 1.0653e-38, 9.5510e-39],\n",
      "        [1.0561e-38, 1.0194e-38, 1.1112e-38],\n",
      "        [1.0561e-38, 9.9184e-39, 1.0653e-38],\n",
      "        [4.1327e-39, 1.0194e-38, 1.0469e-38]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(5,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e546eaac",
   "metadata": {},
   "source": [
    "  创建一个5*3的long型全0的tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dea0107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(5, 3, dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee67f76",
   "metadata": {},
   "source": [
    "可以使用shape属性或size方法来获取tensor的形状,返回一个元组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d88d61bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "# x.size()\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b45137",
   "metadata": {},
   "source": [
    "## 2.操作 \n",
    "### 1. 加法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "740277f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1371, 0.6264, 0.8099],\n",
      "        [0.2090, 0.6607, 0.5775],\n",
      "        [0.9998, 0.4596, 0.2482],\n",
      "        [0.6568, 0.3034, 0.9711],\n",
      "        [0.3780, 0.7060, 0.0399]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.rand(5,3)\n",
    "result = torch.empty(5, 3)\n",
    "# print(x+y)\n",
    "# print(torch.add(x, y, out=result))\n",
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46def5e",
   "metadata": {},
   "source": [
    "### 2.索引\n",
    "索引出来的数据与原数据共享内存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c96a4a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1]) \n",
      " tensor([1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "y = x[0, :]\n",
    "y += 1\n",
    "print(y, '\\n', x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3144ff5",
   "metadata": {},
   "source": [
    "改变形状： 使用view来改变形状—— 同样的，view()也是与原数据共享内存，仅仅是改变观察角度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79069690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3]) torch.Size([15]) torch.Size([3, 5])\n"
     ]
    }
   ],
   "source": [
    "y = x.view(15)\n",
    "z = x.view(-1,5)\n",
    "print(x.shape, y.shape, z.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78343656",
   "metadata": {},
   "source": [
    "  如果想返回一个真正的副本，应该先使用.clone()来返回一个副本，在使用.view()来改变形状  \n",
    " 使用clone的另一个好处是**结果会保存在计算图中，即梯度回传到副本时也会传到源tensor**  \n",
    " 不推荐使用reshape,因为此函数并不保证返回的是其拷贝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66d30dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  0,  0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]) \n",
      " tensor([[-1, -1, -1],\n",
      "        [-2, -2, -2],\n",
      "        [-2, -2, -2],\n",
      "        [-2, -2, -2],\n",
      "        [-2, -2, -2]])\n"
     ]
    }
   ],
   "source": [
    "x_cp = x.clone().view(15)\n",
    "x -= 1\n",
    "print(x_cp, '\\n',  x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dcadc4",
   "metadata": {},
   "source": [
    "另一个常用的函数：item: 将一个标量tensor转换成python num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f33d51ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.5209]) -1.5209071636199951\n"
     ]
    }
   ],
   "source": [
    "z = torch.randn(1)\n",
    "print(z, z.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc1b14f",
   "metadata": {},
   "source": [
    "### 3. 广播机制\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fdf88342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2]])\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3]])\n",
      "tensor([[2, 3],\n",
      "        [3, 4],\n",
      "        [4, 5]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(1,3).view(1,2)\n",
    "print(x)\n",
    "y = torch.arange(1,4).view(3,1)\n",
    "print(y)\n",
    "print(x+y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf202dbc",
   "metadata": {},
   "source": [
    "### 4. 运算的内存开销\n",
    "  索引操作不会开辟新的空间，而像*y = x + y*这样的操作，会开辟新的内存，然后将y指向新的内存。\n",
    "使用python自带的id函数来验证这一点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "18305582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1,2])\n",
    "y = torch.tensor([3,4])\n",
    "id_before = id(y)\n",
    "y = y+x\n",
    "print(id(y) == id_before)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d3c29f",
   "metadata": {},
   "source": [
    "想在原内存中保存结果，可以使用y[:] = ...来做到这一点；或者使用全名运算符中的out参数来做到这一点"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d22f44",
   "metadata": {},
   "source": [
    "### 5. tensor和numpy互换\n",
    "torch.numpy()将tensor转换为nuumpy数组\n",
    "torch.from_numpy()将numpy转换为tensor;——这两种方式共享内存  \n",
    "也可以使用torch.tensor()将numpy转换为tensor，但是返回的tensor与元数据不共享内存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ee3b9956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> <class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1,2])\n",
    "b = a.numpy()\n",
    "c = torch.from_numpy(b)\n",
    "print(type(a),type(b),type(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcef207",
   "metadata": {},
   "source": [
    "### 6. tensor on GPU\n",
    "使用方法 .to() 可将tensor在CPU和GPU之间相互移动"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "951ec324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 3], device='cuda:0')\n",
      "tensor([2., 3.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # GPU\n",
    "    y = torch.ones_like(x, device=device)  # 直接创建在GPU上的tensor\n",
    "    x = x.to(device)  # 等价于 .to(\"cuda\")\n",
    "    z = x+y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
